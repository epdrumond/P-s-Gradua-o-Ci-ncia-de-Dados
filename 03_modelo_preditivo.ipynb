{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ac09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d867a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar dados\n",
    "base = pd.read_csv('base_para_modelo.csv')\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar dados\n",
    "atributos = base.drop(columns = ['id_usuario', 'flag_retido'])\n",
    "target = base['flag_retido']\n",
    "\n",
    "atributos_treino, atributos_validacao, target_treino, target_validacao = train_test_split(\n",
    "    atributos, target,\n",
    "    test_size = 0.1,\n",
    "    stratify = target,\n",
    "    shuffle = True,\n",
    "    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b29372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir função para realizar validação cruzada dos dados\n",
    "def calcular_score_modelo(modelo, dados_treino, dados_validacao, cv):\n",
    "    #Separar dados\n",
    "    x_treino, y_treino = dados_treino\n",
    "    x_validacao, y_validacao = dados_validacao\n",
    "    \n",
    "    #Fazer validação cruzada nos dados de treino\n",
    "    modelo_cv = cross_validate(estimator = modelo, X = x_treino, y = y_treino,\n",
    "                               scoring = ['accuracy', 'roc_auc'],\n",
    "                               cv = cv)\n",
    "    \n",
    "    #Aplicar modelo nos dados de validação\n",
    "    modelo.fit(x_treino, y_treino)\n",
    "    y_pred = modelo.predict(x_validacao)\n",
    "    \n",
    "    #Printar resultados\n",
    "    print('CV model accuracy:  %.3f +/- %.3f'  %(modelo_cv['test_accuracy'].mean(), \n",
    "                                              modelo_cv['test_accuracy'].std()))\n",
    "    print('CV model roc_auc:  %.3f +/- %.3f'  %(modelo_cv['test_roc_auc'].mean(), \n",
    "                                             modelo_cv['test_roc_auc'].std()))\n",
    "    print('Validation accuracy score: %.3f' %accuracy_score(y_validacao, y_pred))\n",
    "    print('Validation ROC_AUC score: %.3f' %roc_auc_score(y_validacao, y_pred))\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb990a",
   "metadata": {},
   "source": [
    "# Modelo Base\n",
    "\n",
    "Vamos começar criando um modelo preditivo simples, através do algoritmo Naive Bayes. O objetivo é ter um parâmetro de comparação para a aplicação de algoritmos de predição mais complexos.\n",
    "\n",
    "A vantagem de utilizar esse algoritmo agora é a inexistência de hiperparâmetros para ajuste, tornando o processo mais rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea864f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular precisão do modelo construído com o algoritmo Naive Bayes\n",
    "naive_bayes = GaussianNB()\n",
    "modelo_01 = calcular_score_modelo(modelo = naive_bayes,\n",
    "                                  dados_treino = (atributos_treino, target_treino),\n",
    "                                  dados_validacao = (atributos_validacao, target_validacao),\n",
    "                                  cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a8ab5c",
   "metadata": {},
   "source": [
    "Os resultados do primeiro modelo apontam para um problema desafiador, especialmente quando focamos naqueles para os dados de validação. Considerando que os registros classificados como sucesso representam cerca de 36% do total, ambos acurácia e área sobre a curva ROC indicam que o algoritmo de Naive Bayes conseguiu produzir um modelo apenas marginalmente superior a uma classificação aleatória.\n",
    "\n",
    "Com isso, passamos para uma modelagem ligeiramente mais sofisticada. Nosso objetivo, no entanto, não será somente de melhorar a precisão da nossa modelagem, mas também obter uma forma de identificar quais atributos são mais e menos importantes para nosso estudo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058f7c0",
   "metadata": {},
   "source": [
    "# Regressão Logística / Seleção de Atributos\n",
    "\n",
    "A escolha da regressão logística para esse segundo passo se dá um simples motivo. Ainda que se trate de um algoritmo mais complexo que o Naive Bayes, essa modelagem ainda é bastante simples de ser compreendida. Isso significa, em última instância,  em um alto nível de interpretabilidade dos seus resultados, o que é um fator relevante quando queremos selecionar atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular precisão do modelo construído com o algoritmo de Regressão Logística\n",
    "reg_logistica = LogisticRegression(solver = 'liblinear')\n",
    "modelo_02 = calcular_score_modelo(modelo = reg_logistica,\n",
    "                                  dados_treino = (atributos_treino, target_treino),\n",
    "                                  dados_validacao = (atributos_validacao, target_validacao),\n",
    "                                  cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28129e",
   "metadata": {},
   "source": [
    "Os resultados mostram uma clara melhora em relação ao modelo anterior. Um outro ponto de destaque é que o modelo parece apresentar poucos problemas de generalização, uma vez que os scores para os dados de validações estão muito próximos daqueles observados nos dados usados na validação cruzada.\n",
    "\n",
    "Vamos então, avaliar a importância de cada feature para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b26c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar importância dos atributos no modelo de Regressão Logística\n",
    "importancia_atributos = pd.DataFrame()\n",
    "importancia_atributos['atributos'] = atributos_treino.columns\n",
    "importancia_atributos['valor_coef'] = list(modelo_02.coef_.reshape(-1))\n",
    "importancia_atributos['valor_coef'] = [abs(valor) for valor in importancia_atributos['valor_coef']]\n",
    "importancia_atributos = importancia_atributos.sort_values(by = 'valor_coef', ascending = False).tail(10)\n",
    "\n",
    "fig = go.Figure([go.Bar(x = importancia_atributos['valor_coef'], y = importancia_atributos['atributos'], \n",
    "                        orientation = 'h')])\n",
    "fig.update_layout(title = 'Regressão Logística / Importância dos Atributos',\n",
    "                  template = 'plotly_white',\n",
    "                  height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe98d00",
   "metadata": {},
   "source": [
    "O gráfico acima nos mostra, de maneira geral, uma ampla distribuição de importâncias entre os atributos. Mais importante do que identificar o valor exato para cada coluna, devemos destacar aqueles campos com baixa ou nenhuma importância para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35745622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicar norma sobre valores de coeficiente dos campos\n",
    "importancia_atributos['valor_coef'] = [abs(x) for x in importancia_atributos['valor_coef']]\n",
    "importancia_atributos = importancia_atributos.sort_values(by = 'valor_coef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933886b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar distribuição dos valores de importância absolutos\n",
    "fig = go.Figure([go.Histogram(x = importancia_atributos['valor_coef'])])\n",
    "fig.update_layout(title = 'Distribuição da Importância Absoluta dos Atributos',\n",
    "                  template = 'plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb7e92",
   "metadata": {},
   "source": [
    "A distribuição acima aponta para uma quantidade significativa de atributos com coeficiente menor que 0.1. Para efeito de comparação, esse valor representa cerca de metade do valor mediano de importância. \n",
    "\n",
    "Eliminar esse grupo de campos por completo seria, portanto, exagerado. O que faremos é identificar os atributos na metade inferior desse agrupamento e eliminá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remover atributos de menor importância na Regressão Logística\n",
    "remover_atributos = importancia_atributos.sort_values(by = 'valor_coef').head(11)['atributos'].values\n",
    "atributos_treino.drop(columns = remover_atributos, inplace = True)\n",
    "atributos_validacao.drop(columns = remover_atributos, inplace = True)\n",
    "print(remover_atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab00857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reavaliar modelo com dados filtrados\n",
    "reg_logistica = LogisticRegression(solver = 'liblinear')\n",
    "modelo_02_1 = calcular_score_modelo(modelo = reg_logistica,\n",
    "                                    dados_treino = (atributos_treino, target_treino),\n",
    "                                    dados_validacao = (atributos_validacao, target_validacao),\n",
    "                                    cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e31e5",
   "metadata": {},
   "source": [
    "Como podemos evidenciar, a remoção dos 11 atributos não produziu qualquer efeito notável na precisão do modelo, e nem na sua capacidade de generalização. Com isso, partimos para a última fase da nosa modelagem, na qual aplicaremos o algoritmo mais sofisticado até o momento e para o qual utilizaremos técnias de otimização de hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7841b",
   "metadata": {},
   "source": [
    "# Random Forest / Otimizando Modelo Através dos Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c515f",
   "metadata": {},
   "source": [
    "Para o modelo final, vamos utilizar o algoritmo Random Forest. Essa escolha se dá principalmente pela alta capacidade de generalização dos modelos originados, dada a construção da previsão através de uma série de modelos menores construídos a partir de amostras aleatórias do conjunto de dados principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular precisão do modelo construído com o algoritmo Random Forest (sem otimização de hiperparâmetros)\n",
    "floresta = RandomForestClassifier()\n",
    "modelo_02 = calcular_score_modelo(modelo = floresta,\n",
    "                                  dados_treino = (atributos_treino, target_treino),\n",
    "                                  dados_validacao = (atributos_validacao, target_validacao),\n",
    "                                  cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad56dc6",
   "metadata": {},
   "source": [
    "Inicialmente, os resultados apresentados pelo modelo gerado a partir do algoritmo Random Forest foram ligeiramente piores que os produzidos pela Regressão Logística. No entanto, como já colocado, vamos avançar no processo de otimização do modelo com o objetivo de garantir uma melhora nas métricas de predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição do espaço de possíveis hiperparâmetros\n",
    "mapa_hparametros = {\n",
    "    'n_estimators': [50, 100, 250, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 2, 3, 5, 10, None],\n",
    "    'min_samples_leaf': [1, 2, 10, 25, 50, 100],\n",
    "    'max_features': ['auto', 'log2', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizar busca aleatório pela melhor configuração de hiperparâmetros\n",
    "rsc = RandomizedSearchCV(estimator = floresta,\n",
    "                         param_distributions = mapa_hparametros,\n",
    "                         n_iter = 10,\n",
    "                         scoring = ['accuracy', 'roc_auc'],\n",
    "                         n_jobs = 3,\n",
    "                         cv = 5,\n",
    "                         refit = 'accuracy',\n",
    "                         verbose = 1)\n",
    "\n",
    "busca_hparametros = rsc.fit(atributos_treino, target_treino)\n",
    "print(busca_hparametros.best_score_)\n",
    "floresta_v2 = busca_hparametros.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validar resultados para o melhor estimador encontrado pela busca dos hiperparâmetros\n",
    "modelo_03 = calcular_score_modelo(modelo = floresta_v2,\n",
    "                                  dados_treino = (atributos_treino, target_treino),\n",
    "                                  dados_validacao = (atributos_validacao, target_validacao),\n",
    "                                  cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613c752",
   "metadata": {},
   "source": [
    "Como podemos ver, a otimização através dos hiperparâmetros permitiu que encontrássemos um modelo ainda mais preciso que os melhores resultados obtidos anteriormente. Utilizaremos esse modelo de agora em diante para intepretar os resultados da predição e entender como estes podem ser utilizados.\n",
    "\n",
    "No entanto, não vamos utilizar aqui os valores de predição binários, mas o um valor contínuo entre 0 e 1, que representa a probabilidade de que cada registro se adeque na condição de sucesso da nossa análise. Adotamos essa estratégia por nos dar capacidade de utilizar as previsões de maneira mais sofisticada, criando segmentações de clientes de acordo com probabilidade de retenção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cc642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular as previsões para os dados de validação\n",
    "previsao = modelo_03.predict_proba(atributos_validacao)\n",
    "previsao = [x[1] for x in previsao]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar distribuição dos valores de previsão\n",
    "fig = go.Figure([go.Histogram(x = previsao, nbinsx = 30)])\n",
    "fig.update_layout(title = 'Distribuição da Variável Resposta do Modelo de Previsão de Retenção', \n",
    "                  template = 'plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28813dbd",
   "metadata": {},
   "source": [
    "Analisando a distribuição dos valores previstos para a variável objetivo, temos que uma porção significativa dos casos se posicionam numa região mais central, na qual uma simples previsão binária está mais propensa a errar. Isso reforça nossa escolha pela estratégia adotada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
